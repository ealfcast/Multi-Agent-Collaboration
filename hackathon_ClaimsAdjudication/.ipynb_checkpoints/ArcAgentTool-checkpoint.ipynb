{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example for usage ARc Policy via a tool for a Strands Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, this will allow for the restart of the notebook\n",
    "\n",
    "from IPython.display import display_html\n",
    "def restart_kernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)\n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.hooks import HookProvider, HookRegistry, MessageAddedEvent\n",
    "from pydantic import BaseModel\n",
    "import boto3\n",
    "from botocore.config import Config as BotocoreConfig\n",
    "from strands.telemetry import StrandsTelemetry\n",
    "import logging\n",
    "\n",
    "# Configure the root strands logger\n",
    "logging.getLogger(\"strands\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Add a handler to see the logs\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\", \n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Setup tracing - commented out for now as this adds a lot of trace output that really isn't interesting\n",
    "StrandsTelemetry().setup_console_exporter()\n",
    "\n",
    "# NOTE: To send the OTEL data to an ADOT collector, additional exporter needs to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply the pre-installed polciy and guardrail IDs\n",
    "ARC_POLICY_ID = \"<REPLACE ME>\"\n",
    "GUARDRAIL_ID = \"<REPLACE ME>\"\n",
    "GUARDRAIL_VERSION = \"<REPLACE ME>\"\n",
    "# NOTE: the default model for Strands is us.anthropic.claude-sonnet-4-20250514-v1:0\n",
    "MODEL_ID = \"us.amazon.nova-lite-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a notification hook to listen to events and then process the result and call\n",
    "# Automated Reasoning attached via the Guardrail and report on the findings.  This\n",
    "# can be used possibly re-write the output or add a flag on if the output is correct.\n",
    "class NotifyOnlyGuardrailsHook(HookProvider):\n",
    "    \n",
    "    def __init__(self, guardrail_id: str, guardrail_version: str):\n",
    "        self.guardrail_id = guardrail_id\n",
    "        self.guardrail_version = guardrail_version\n",
    "        self.bedrock_client = boto3.client(\"bedrock-runtime\")\n",
    "        self.input = ''\n",
    "        self.response_valid = True\n",
    "\n",
    "    def register_hooks(self, registry: HookRegistry) -> None:\n",
    "        registry.add_callback(MessageAddedEvent, self.process_message)\n",
    "\n",
    "\n",
    "    def evaluate_content(self, content: str, source: str = \"INPUT\"):\n",
    "        \"\"\"Evaluate content using Bedrock ApplyGuardrail API in shadow mode.\"\"\"\n",
    "\n",
    "        # User input, no need to call the guardrail in this case yet\n",
    "        if source == \"INPUT\":\n",
    "            self.input = content\n",
    "            return\n",
    "        \n",
    "        # Format a request to send to the guardrail\n",
    "        content_to_validate = [\n",
    "            {\"text\": {\"text\": self.input, \"qualifiers\": [\"query\"]}},\n",
    "            {\"text\": {\"text\": content, \"qualifiers\": [\"guard_content\"]}}\n",
    "        ]\n",
    "        \n",
    "        # Call the guardrail\n",
    "        response = self.bedrock_client.apply_guardrail(\n",
    "            guardrailIdentifier=self.guardrail_id,\n",
    "            guardrailVersion=self.guardrail_version,\n",
    "            source=\"OUTPUT\",\n",
    "            content=content_to_validate\n",
    "        )\n",
    "\n",
    "        # Determine if the output is safe\n",
    "        assessments = response.get(\"assessments\", [])\n",
    "        if assessments and len(assessments):\n",
    "            arcpolicy = assessments[0].get(\"automatedReasoningPolicy\", [])\n",
    "\n",
    "            if arcpolicy and len(arcpolicy):\n",
    "                findings = arcpolicy.get(\"findings\", [])\n",
    "\n",
    "                if findings and len(findings):\n",
    "                    self.response_valid = False\n",
    "        \n",
    "    def process_message(self, event: MessageAddedEvent) -> None:\n",
    "        \"\"\"Check message and determine if it's user or assistant created.\"\"\"\n",
    "\n",
    "        # Get the content\n",
    "        content = \"\".join(block.get(\"text\", \"\") for block in event.message.get(\"content\", []))\n",
    "\n",
    "        # Determine the source\n",
    "        source = \"INPUT\"\n",
    "        if event.message.get(\"role\") == \"assistant\":\n",
    "            source = \"OUTPUT\"\n",
    "        \n",
    "        # Call the eval function to determine if something should be done\n",
    "        self.evaluate_content(content, source)\n",
    "\n",
    "        # In the case of output and the arc findings are in place, signal that to the caller\n",
    "        if source == \"OUTPUT\":\n",
    "            # Add information to the output\n",
    "            new_output = content + f\"\\n\\nresponse_valid: {self.response_valid}\"\n",
    "            event.message[\"content\"][0][\"text\"] = new_output\n",
    "\n",
    "# Create structured output\n",
    "class ArcValidationCheck(BaseModel):\n",
    "    response_valid: bool\n",
    "    content: str\n",
    "\n",
    "# Provide the config for botocore\n",
    "boto_config = BotocoreConfig(\n",
    "    retries={\"max_attempts\": 3, \"mode\": \"standard\"},\n",
    "    connect_timeout=5,\n",
    "    read_timeout=60\n",
    ")\n",
    "\n",
    "# Create a Bedrock model with guardrail configuration\n",
    "bedrock_model = BedrockModel(\n",
    "    boto_client_config=boto_config,\n",
    "    model_id=MODEL_ID,\n",
    "    # NOTE: An alternative option is to supply the guardrail here.  If going that route, the ARc findings aren't present.\n",
    "    # To ensure that the findings are present and can be used to re-write the output, rely on a hook\n",
    ")\n",
    "\n",
    "# Create agent with the guardrail-protected model\n",
    "auto_policy_agent = Agent(\n",
    "    system_prompt=\"You are a helpful assistant that will answer questions related to auto insurance policy.\",\n",
    "    model=bedrock_model,\n",
    "    hooks=[NotifyOnlyGuardrailsHook(GUARDRAIL_ID, GUARDRAIL_VERSION)],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the protected agent for conversations\n",
    "auto_policy_agent(\"If I have a trailer and I get into an accident is that considered a separate vehicle?\")\n",
    "\n",
    "# Get the structured output.  Without providing a prompt, the agent will act on conversation history to get the response\n",
    "response = auto_policy_agent.structured_output(ArcValidationCheck)\n",
    "\n",
    "# Extract the findings from the response\n",
    "print(f\"response.response_valid = {response.response_valid}\")\n",
    "print(f\"repsonse.content = {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
