{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example for usage ARc Policy via a Strands Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T22:45:51.328743Z",
     "iopub.status.busy": "2025-10-23T22:45:51.328422Z",
     "iopub.status.idle": "2025-10-23T22:45:55.317724Z",
     "shell.execute_reply": "2025-10-23T22:45:55.316813Z",
     "shell.execute_reply.started": "2025-10-23T22:45:51.328714Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-23T22:45:55.995Z",
     "iopub.execute_input": "2025-10-23T22:45:55.319095Z",
     "iopub.status.busy": "2025-10-23T22:45:55.318831Z"
    }
   },
   "outputs": [],
   "source": [
    "# If needed, this will allow for the restart of the notebook\n",
    "\n",
    "from IPython.display import display_html\n",
    "def restart_kernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)\n",
    "restart_kernel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T22:46:01.291918Z",
     "iopub.status.busy": "2025-10-23T22:46:01.291629Z",
     "iopub.status.idle": "2025-10-23T22:46:01.783461Z",
     "shell.execute_reply": "2025-10-23T22:46:01.782695Z",
     "shell.execute_reply.started": "2025-10-23T22:46:01.291894Z"
    }
   },
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.hooks import HookProvider, HookRegistry, MessageAddedEvent, BeforeModelCallEvent, BeforeToolCallEvent\n",
    "from pydantic import BaseModel\n",
    "import boto3\n",
    "from botocore.config import Config as BotocoreConfig\n",
    "from strands.telemetry import StrandsTelemetry\n",
    "from findings_utils import extract_reasoning_findings\n",
    "import logging\n",
    "from strands_tools import retrieve\n",
    "import os\n",
    "\n",
    "# Configure the root strands logger\n",
    "logging.getLogger(\"strands\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Add a handler to see the logs\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\", \n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Setup tracing - commented out for now as this adds a lot of trace output that really isn't interesting\n",
    "StrandsTelemetry().setup_console_exporter()\n",
    "\n",
    "# NOTE: To send the OTEL data to an ADOT collector, additional exporter needs to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide values for the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T22:46:03.091758Z",
     "iopub.status.busy": "2025-10-23T22:46:03.091341Z",
     "iopub.status.idle": "2025-10-23T22:46:03.096153Z",
     "shell.execute_reply": "2025-10-23T22:46:03.095168Z",
     "shell.execute_reply.started": "2025-10-23T22:46:03.091728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Supply the pre-installed polciy and guardrail IDs\n",
    "ARC_POLICY_ARN = \"<REPLACE ME>\"\n",
    "GUARDRAIL_ID = \"<REPLACE ME>\"\n",
    "GUARDRAIL_VERSION = \"<REPLACE ME>\"\n",
    "KNOWLEDGE_BASE_ID = \"<REPLACE_ME>\"\n",
    "# NOTE: the default model for Strands is us.anthropic.claude-sonnet-4-20250514-v1:0\n",
    "MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "# MODEL_ID = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment for the agent and tool\n",
    "# Allow for the metadata to be retrieved on sources from the KB\n",
    "os.environ['RETRIEVE_ENABLE_METADATA_DEFAULT'] = 'true'\n",
    "# Allow for the retrieve tool to interact with the KB\n",
    "os.environ['KNOWLEDGE_BASE_ID'] = KNOWLEDGE_BASE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T22:46:05.005310Z",
     "iopub.status.busy": "2025-10-23T22:46:05.005018Z",
     "iopub.status.idle": "2025-10-23T22:46:05.493518Z",
     "shell.execute_reply": "2025-10-23T22:46:05.492699Z",
     "shell.execute_reply.started": "2025-10-23T22:46:05.005287Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a notification hook to listen to events and then process the result and call\n",
    "# Automated Reasoning attached via the Guardrail and report on the findings.  This\n",
    "# can be used possibly re-write the output or add a flag on if the output is correct.\n",
    "class NotifyOnlyGuardrailsHook(HookProvider):\n",
    "    \n",
    "    def __init__(self, guardrail_id: str, guardrail_version: str, arc_policy_arn: str):\n",
    "        self.guardrail_id = guardrail_id\n",
    "        self.guardrail_version = guardrail_version\n",
    "        self.arc_policy_arn = arc_policy_arn\n",
    "        self.bedrock_client = boto3.client(\"bedrock-runtime\")\n",
    "        self.input = ''\n",
    "        self.claim_valid = True\n",
    "        self.findings = ''\n",
    "        self.policy_definition = {}\n",
    "        self.before_tool_event_flag = False\n",
    "        self.before_model_event_flag = False\n",
    "\n",
    "        if self.arc_policy_arn:\n",
    "            try:\n",
    "                bedrock_client = boto3.client('bedrock')\n",
    "                response = bedrock_client.export_automated_reasoning_policy_version(policyArn=self.arc_policy_arn)\n",
    "                self.policy_definition = response.get('policyDefinition', {})\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting policy definition: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "    def register_hooks(self, registry: HookRegistry) -> None:\n",
    "        registry.add_callback(BeforeModelCallEvent, self.before_model_event)\n",
    "        registry.add_callback(BeforeToolCallEvent, self.before_tool_event)\n",
    "        registry.add_callback(MessageAddedEvent, self.message_added)\n",
    "\n",
    "    def message_added(self, event: MessageAddedEvent) -> None:\n",
    "        if self.before_tool_event_flag:\n",
    "            # Since a tool was called, just ignore this message addition\n",
    "            self.before_tool_event_flag = False\n",
    "            return\n",
    "        \n",
    "        # Get the content\n",
    "        content = \"\".join(block.get(\"text\", \"\") for block in event.message.get(\"content\", []))\n",
    "\n",
    "        # Determine the source\n",
    "        if event.message.get(\"role\") == \"user\":\n",
    "            # Store the input for later usage and allow the loop to continue to process\n",
    "            self.input = content\n",
    "            return\n",
    "\n",
    "        # Capture if this is the first time that findings will be created\n",
    "        first_findings = (not self.findings)\n",
    "\n",
    "        # Format a request to send to the guardrail\n",
    "        content_to_validate = [\n",
    "            {\"text\": {\"text\": self.input, \"qualifiers\": [\"query\"]}},\n",
    "            {\"text\": {\"text\": content, \"qualifiers\": [\"guard_content\"]}}\n",
    "        ]\n",
    "\n",
    "        # Call the guardrail\n",
    "        response = self.bedrock_client.apply_guardrail(\n",
    "            guardrailIdentifier=self.guardrail_id,\n",
    "            guardrailVersion=self.guardrail_version,\n",
    "            source=\"OUTPUT\",\n",
    "            content=content_to_validate\n",
    "        )\n",
    "\n",
    "        # Determine if the output is correct\n",
    "        self.findings = extract_reasoning_findings(response, self.policy_definition)\n",
    "         \n",
    "        assessments = response.get(\"assessments\", [])\n",
    "        if assessments and len(assessments):\n",
    "            self.claim_valid = False\n",
    "\n",
    "        # Add information to the output\n",
    "        if self.findings and first_findings:\n",
    "            new_output = content\n",
    "            new_output = new_output + f\"\\n\\nfindings: {self.findings}\"\n",
    "            new_output = new_output + f\"\\n\\nclaim_valid: {self.claim_valid}\"\n",
    "            event.message[\"content\"][0][\"text\"] = new_output\n",
    "        \n",
    "    def before_model_event(self, event: BeforeModelCallEvent) -> None:\n",
    "        self.before_model_event_flag = True\n",
    "\n",
    "    def before_tool_event(self, event: BeforeToolCallEvent) -> None:\n",
    "        self.before_tool_event_flag = True\n",
    "\n",
    "# Create structured output\n",
    "class StructuredOutputModel(BaseModel):\n",
    "    claim_valid: bool\n",
    "    content: str\n",
    "    findings: str\n",
    "\n",
    "# Provide the config for botocore\n",
    "boto_config = BotocoreConfig(\n",
    "    retries={\"max_attempts\": 3, \"mode\": \"standard\"},\n",
    "    connect_timeout=5,\n",
    "    read_timeout=60\n",
    ")\n",
    "\n",
    "# Create a Bedrock model with guardrail configuration\n",
    "bedrock_model = BedrockModel(\n",
    "    boto_client_config=boto_config,\n",
    "    model_id=MODEL_ID,\n",
    "    # NOTE: An alternative option is to supply the guardrail here.  If going that route, the ARc findings aren't present.\n",
    "    # To ensure that the findings are present and can be used to re-write the output, rely on a hook\n",
    ")\n",
    "\n",
    "# Create agent with the guardrail-protected model\n",
    "auto_policy_agent = Agent(\n",
    "    system_prompt=\"You are an assistant that determines if the users auto insurance claim is valid based on the provided information and details within the policy contract. In cases where a clear outcome is not present ask the user to check with their insurance agent. Take your time to think though the answer and evalute carefully.\",\n",
    "    model=bedrock_model,\n",
    "    hooks=[NotifyOnlyGuardrailsHook(GUARDRAIL_ID, GUARDRAIL_VERSION, ARC_POLICY_ARN)],\n",
    "    tools=[retrieve]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T22:46:08.755890Z",
     "iopub.status.busy": "2025-10-23T22:46:08.755606Z",
     "iopub.status.idle": "2025-10-23T22:46:40.193259Z",
     "shell.execute_reply": "2025-10-23T22:46:40.192347Z",
     "shell.execute_reply.started": "2025-10-23T22:46:08.755867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ask the agent a question\n",
    "auto_policy_agent(\"I was delivering goods for my company using my personal car. I got into an accident, this was over 3 months ago. Does my policy cover this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the structured output.  Without providing a prompt, the agent will act on conversation history to get the response\n",
    "response = auto_policy_agent.structured_output(StructuredOutputModel)\n",
    "\n",
    "# Extract the findings from the response\n",
    "print(f\"response.claim_valid = {response.claim_valid}\")\n",
    "print(f\"repsonse.content = {response.content}\")\n",
    "print(f\"repsonse.findings = {response.findings}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
