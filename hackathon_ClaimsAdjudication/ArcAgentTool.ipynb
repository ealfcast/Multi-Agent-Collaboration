{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example for usage ARc Policy via a tool for a Strands Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.hooks import HookProvider, HookRegistry, MessageAddedEvent\n",
    "import boto3\n",
    "from botocore.config import Config as BotocoreConfig\n",
    "from strands.telemetry import StrandsTelemetry\n",
    "import logging\n",
    "\n",
    "# Configure the root strands logger\n",
    "logging.getLogger(\"strands\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Add a handler to see the logs\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\", \n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Setup tracing - commented out for now as this adds a lot of trace output that really isn't interesting\n",
    "# StrandsTelemetry().setup_console_exporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply the pre-installed polciy and guardrail IDs\n",
    "ARC_POLICY_ID = \"<REPLACE ME>\"\n",
    "GUARDRAIL_ID = \"<REPLACE ME>\"\n",
    "GUARDRAIL_VERSION = \"<REPLACE ME>\"\n",
    "# MODEL_ID = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "MODEL_ID = \"us.amazon.nova-lite-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class NotifyOnlyGuardrailsHook(HookProvider):\n",
    "    def __init__(self, guardrail_id: str, guardrail_version: str):\n",
    "        self.guardrail_id = guardrail_id\n",
    "        self.guardrail_version = guardrail_version\n",
    "        self.bedrock_client = boto3.client(\"bedrock-runtime\")\n",
    "        self.input = ''\n",
    "\n",
    "    def register_hooks(self, registry: HookRegistry) -> None:\n",
    "        registry.add_callback(MessageAddedEvent, self.process_message)\n",
    "\n",
    "\n",
    "    def evaluate_content(self, content: str, source: str = \"INPUT\"):\n",
    "        \"\"\"Evaluate content using Bedrock ApplyGuardrail API in shadow mode.\"\"\"\n",
    "        print(f\"[GUARDRAIL] [evaluate_content]: source: {source}, content: {content}\")\n",
    "        \n",
    "        # User input, no need to call the guardrail in this case yet\n",
    "        if source == \"INPUT\":\n",
    "            self.input = content\n",
    "            return\n",
    "        \n",
    "        # Format a request to send to the guardrail\n",
    "        content_to_validate = [\n",
    "            {\"text\": {\"text\": self.input, \"qualifiers\": [\"query\"]}},\n",
    "            {\"text\": {\"text\": content, \"qualifiers\": [\"guard_content\"]}}\n",
    "        ]\n",
    "\n",
    "        print(f\"[GUARDRAIL] [evaluate_content] Attempting to determine if the LLM output is safe.\")\n",
    "        \n",
    "        # Call the guardrail\n",
    "        response = self.bedrock_client.apply_guardrail(\n",
    "            guardrailIdentifier=self.guardrail_id,\n",
    "            guardrailVersion=self.guardrail_version,\n",
    "            source=\"OUTPUT\",\n",
    "            content=content_to_validate\n",
    "        )\n",
    "\n",
    "        print(f\"[GUARDRAIL] [evaluate_content] response: {response}\")\n",
    "\n",
    "        # TODO Include re-writing the response here\n",
    "        \n",
    "    def process_message(self, event: MessageAddedEvent) -> None:\n",
    "        \"\"\"Check message and determine if it's user or assistant created.\"\"\"\n",
    "        print (f'[GUARDRAIL] [process_message] event: {event}')\n",
    "\n",
    "        # Get the content\n",
    "        content = \"\".join(block.get(\"text\", \"\") for block in event.message.get(\"content\", []))\n",
    "\n",
    "        # Determine the source\n",
    "        source = \"INPUT\"\n",
    "        if event.message.get(\"role\") == \"assistant\":\n",
    "            source = \"OUTPUT\"\n",
    "        \n",
    "        # Call the eval function to determine if something should be done\n",
    "        self.evaluate_content(content, source)\n",
    "\n",
    "# Provide the config for botocore\n",
    "boto_config = BotocoreConfig(\n",
    "    retries={\"max_attempts\": 3, \"mode\": \"standard\"},\n",
    "    connect_timeout=5,\n",
    "    read_timeout=60\n",
    ")\n",
    "\n",
    "# Create a Bedrock model with guardrail configuration\n",
    "bedrock_model = BedrockModel(\n",
    "    boto_client_config=boto_config,\n",
    "    model_id=MODEL_ID,\n",
    "    # NOTE: An alternative option is to supply the guardrail here.  If going that route, the ARc findgins aren't present.\n",
    "    # To ensure that the findings are present and can be used to re-write the output, rely on a hook\n",
    ")\n",
    "\n",
    "# Create agent with the guardrail-protected model\n",
    "auto_policy_agent = Agent(\n",
    "    system_prompt=\"You are a helpful assistant that will answer questions related to auto insurance policy.\",\n",
    "    model=bedrock_model,\n",
    "    hooks=[NotifyOnlyGuardrailsHook(GUARDRAIL_ID, GUARDRAIL_VERSION)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the protected agent for conversations\n",
    "response = auto_policy_agent(\"If I have a trailer and I get into an accident is that considered a separate vehicle?\")\n",
    "\n",
    "# TODO Do something with the response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
